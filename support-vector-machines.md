Support Vector Machines (SVMs) are supervised models that are particularly adept at handling non-linearly separable data. 

Brief overview of key components:
- **Margin Maximization**: SVMs seek a decision boundary with the widest margin between classes. This promotes robust generalization, reducing the risk of overfitting and enhancing performance on unseen data.
- The **hinge loss function** helps SVMs strike a balance between accurate training classification and future prediction. It prioritizes classifying "hard" data points closer to the decision boundary.
- SVMs employ the **kernel trick**, transforming data into higher dimensions without explicit computation. This empowers SVMs to handle non-linearly separable data, offering solutions even in complex scenarios.

![[Pasted image 20231010111235.png]]

[[learning-algorithms]]